# SageAlpha Chat â€” Project Files (Fixed)

Below are the corrected, ready-to-run project files. Copy these into your project folder structure exactly as shown, install requirements, set environment variables, and run.

---

## `app.py`

```python
#!/usr/bin/env python3
"""
Flask Chat App â€” Fixed and ready to run.
Supports Azure OpenAI (if env vars set) and falls back to mock mode.
"""

import os
from datetime import datetime
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from dotenv import load_dotenv

# Use the new official OpenAI Python client
# pip install openai
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# Load .env when present
load_dotenv()

app = Flask(__name__)
CORS(app)
app.secret_key = os.environ.get("FLASK_SECRET_KEY", "dev-secret")

# In-memory chat history (for demo only). Each entry is {role: 'user'|'assistant', content: '...'}
chat_history = []

# Initialize OpenAI client (Azure-compatible)
client = None
openai_mode = "mock"

AZURE_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4.1"))
AZURE_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")

if OpenAI and AZURE_API_KEY and AZURE_ENDPOINT:
    try:
        # The OpenAI client expects the base URL for Azure as the `base_url` when using the OpenAI Python package.
        client = OpenAI(api_key=AZURE_API_KEY, base_url=AZURE_ENDPOINT, api_type="azure", api_version=AZURE_API_VERSION)
        openai_mode = "real"
    except Exception as e:
        print(f"Warning: OpenAI initialization failed: {e}")
        client = None
else:
    if not OpenAI:
        print("Warning: `openai` Python package is not available. Install with: pip install openai")
    else:
        print("Warning: Azure OpenAI env vars not fully set. Running in mock mode.")


@app.route("/")
def home():
    return render_template("index.html")


@app.route("/chat", methods=["POST"])
def chat():
    data = request.get_json(force=True)

    if not data or "message" not in data:
        return jsonify({"error": "Missing 'message' field"}), 400

    user_msg = str(data.get("message", "")).strip()
    if not user_msg:
        return jsonify({"error": "Empty message"}), 400

    # Append user message to history
    chat_history.append({"role": "user", "content": user_msg})

    # Keep only last N messages to avoid large payloads
    MAX_TURNS = 20
    if len(chat_history) > MAX_TURNS:
        del chat_history[:-MAX_TURNS]

    reply = None

    if client is not None:
        try:
            # Build messages payload with a system prompt + history
            messages = [{"role": "system", "content": "You are a helpful, concise assistant. Keep replies under 200 words."}]
            # Convert our chat_history to the shape expected by the API
            for m in chat_history:
                # ensure role and content are strings
                role = m.get("role")
                content = m.get("content")
                if role and content:
                    messages.append({"role": role, "content": content})

            # Create the chat completion using Azure deployment name as model
            resp = client.chat.completions.create(
                model=AZURE_DEPLOYMENT,
                messages=messages,
                max_tokens=200,
                temperature=0.7,
            )

            # Defensive parsing of response
            reply = None
            if hasattr(resp, "choices") and len(resp.choices) > 0:
                choice = resp.choices[0]
                # Newer client shape uses .message.content
                if hasattr(choice, "message") and getattr(choice.message, "content", None) is not None:
                    reply = choice.message.content.strip()
                # older or alternative shapes
                elif getattr(choice, "text", None) is not None:
                    reply = choice.text.strip()

            if not reply:
                reply = "(AI returned an empty reply â€” try again or use a different prompt)"

        except Exception as e:
            print(f"OpenAI API error: {e}")
            reply = f"Sorry, AI service temporarily unavailable: {str(e)[:200]}"
    else:
        # Mock reply
        reply = f"ðŸ¤– (Mock) You said: {user_msg}"

    # Append assistant reply to history
    chat_history.append({"role": "assistant", "content": reply})

    return jsonify({"response": reply}), 200


@app.route("/reset", methods=["POST"])
def reset():
    chat_history.clear()
    return jsonify({"status": "cleared"}), 200


@app.route("/health")
def health():
    return jsonify({
        "status": "ok",
        "messages": len(chat_history),
        "rag_enabled": False,
        "ai_mode": openai_mode,
        "time": datetime.utcnow().isoformat() + "Z",
    })


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    debug = os.environ.get("FLASK_DEBUG", "False").lower() == "true"
    print(f"ðŸš€ Running on http://0.0.0.0:{port} (AI Mode: {openai_mode})")
    app.run(host="0.0.0.0", port=port, debug=debug)
```

---

## `templates/index.html`

> Put this file in `templates/index.html` (Flask expects Jinja templates in `templates/`).

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>SageAlpha.ai Chat</title>
  <style>
    /* same CSS as you provided, minor improvements for accessibility */
    body { font-family: "Segoe UI", sans-serif; background: linear-gradient(135deg, #667eea, #764ba2); color: white; height: 100vh; margin: 0; display: flex; justify-content: center; align-items: center; }
    .chat-box { background: white; color: #333; border-radius: 12px; width: 90%; max-width: 600px; height: 600px; display: flex; flex-direction: column; box-shadow: 0 10px 40px rgba(0,0,0,0.2); overflow: hidden; }
    .header { background: linear-gradient(135deg, #667eea, #764ba2); padding: 15px; text-align: center; color: #fff; font-weight: bold; font-size: 1.2rem; }
    .messages { flex: 1; padding: 15px; overflow-y: auto; background: #f7f7f7; }
    .msg { margin-bottom: 10px; padding: 10px 15px; border-radius: 10px; max-width: 80%; }
    .user { background: #667eea; color: white; align-self: flex-end; }
    .assistant { background: #e0e0e0; align-self: flex-start; }
    .input-area { display: flex; border-top: 1px solid #ddd; }
    input { flex: 1; padding: 10px; border: none; outline: none; font-size: 1rem; }
    button { width: 80px; border: none; background: #667eea; color: white; font-weight: bold; cursor: pointer; }
    button:hover { background: #556cd6; }
    .reset-btn { width: 80px; background: #ff6b6b; }
    .reset-btn:hover { background: #ff5252; }
  </style>
</head>
<body>
  <div class="chat-box">
    <div class="header">ðŸ’¬ SageAlpha.ai</div>
    <div class="messages" id="messages" aria-live="polite"></div>
    <div class="input-area">
      <input type="text" id="messageInput" placeholder="Type your message..." aria-label="Message input" />
      <button onclick="sendMessage()">Send</button>
      <button class="reset-btn" onclick="resetChat()">Reset</button>
    </div>
  </div>

  <script>
    const messagesDiv = document.getElementById("messages");
    const input = document.getElementById("messageInput");

    async function sendMessage() {
      const text = input.value.trim();
      if (!text) return;

      addMessage("user", text);
      input.value = "";
      input.focus();

      try {
        const res = await fetch("/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: text }),
        });

        if (!res.ok) {
          const err = await res.json().catch(() => ({}));
          addMessage("assistant", "âš ï¸ Error: " + (err.error || res.statusText));
          return;
        }

        const data = await res.json();
        if (data.response) addMessage("assistant", data.response);
        else addMessage("assistant", "âš ï¸ Error: " + (data.error || "No response"));
      } catch (e) {
        addMessage("assistant", "âš ï¸ Network error: " + e.message);
      }
    }

    async function resetChat() {
      await fetch("/reset", { method: "POST" });
      messagesDiv.innerHTML = "";
    }

    function addMessage(role, text) {
      const div = document.createElement("div");
      div.className = `msg ${role}`;
      div.textContent = text;
      messagesDiv.appendChild(div);
      messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }

    input.addEventListener("keypress", (e) => {
      if (e.key === "Enter") sendMessage();
    });
  </script>
</body>
</html>
```

---

## `.env.example`

```
# Copy to .env and set values
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com
AZURE_OPENAI_API_KEY=your_azure_openai_key_here
AZURE_OPENAI_DEPLOYMENT=gpt-4.1
AZURE_OPENAI_API_VERSION=2024-08-01-preview

FLASK_SECRET_KEY=replace-with-a-secure-random-string
PORT=8000
FLASK_DEBUG=True

# Optional
PDF_FOLDER_PATH=assets/Sanghvi Movers Limited
COMPANY_NAME=Sanghvi Movers Limited
```

---

## `requirements.txt`

```
flask>=3.0.0
flask-cors>=4.0.0
python-dotenv>=1.0.0
openai>=1.0.0
gunicorn>=23.0.0
requests>=2.32.0
PyPDF2>=3.0.0
sentence-transformers>=2.2.2
faiss-cpu>=1.8.0
numpy>=1.25.0
```

---

## `README.md` (quick run steps)

```
1. Create a virtualenv and activate it:
   python -m venv venv
   source venv/bin/activate   # Linux/macOS
   venv\Scripts\activate    # Windows

2. Install packages:
   pip install -r requirements.txt

3. Copy `.env.example` to `.env` and fill your Azure OpenAI credentials.

4. Run the app:
   python app.py

5. Open http://localhost:8000 on your browser.
```

---

### Notes â€” what I fixed and why

* Robust OpenAI initialization: uses `OpenAI(api_key=..., base_url=..., api_type='azure', api_version=...)` when Azure vars are present.
* Defensive handling of API responses to support slight differences in response objects.
* Ensured `.env` variable names are consistent and documented in `.env.example`.
* Added `flask-cors` usage so your front-end can call endpoints when deployed from other origins.
* Kept an in-memory history for demo. For production, use a DB or Redis.
* Simplified and grouped requirements to avoid version conflicts.

---

If you want, I can now:

* produce a zip file of these files for download,
* or convert `README` into a runbook for Azure App Service deployment,
* or add PDF-reading / RAG functionality (you had sentence-transformers/faiss listed) â€” tell me which.

*Files created above are available in the editor panel to copy.*
